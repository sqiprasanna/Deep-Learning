{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoGAN_final.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "MIL-ko3BMF_q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ag5otWjuNYPl",
        "colab_type": "code",
        "outputId": "b67e5aa5-edea-4cd6-f633-f7814764eae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JvNADFg6xXk8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cd \"/content/drive/My Drive/Colab Notebooks\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OjaUUKE22-OW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/My Drive/Colab Notebooks/faces94\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MJ44I8h73H2i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob as glob\n",
        "image_paths = glob.glob(file_path+'/*/*/*.jp*g')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3CnPboiY3PYV",
        "colab_type": "code",
        "outputId": "6ebb9b51-305c-4479-f79e-098d0669fb87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(image_paths)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3059"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "6sNvbKmD3U2-",
        "colab_type": "code",
        "outputId": "283751a1-235f-4f52-e500-b8962bb43532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import keras\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam,RMSprop\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Convolution2D, Dropout, Flatten, Dense, BatchNormalization, Reshape, UpSampling2D, Activation, AveragePooling2D, MaxPooling2D\n",
        "from keras.optimizers import Adam, sgd\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.regularizers import L1L2\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import transform\n",
        "import sys\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zlahk8uu0FVr",
        "colab_type": "code",
        "outputId": "1402e56b-530d-45a3-e711-f1551af911e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "image_transform = (128, 128, 3)\n",
        "images = np.empty((len(image_paths), *image_transform))\n",
        "for i in range(len(image_paths)//3):\n",
        "    img = plt.imread(image_paths[i])\n",
        "    transformed_img = transform.resize(img, image_transform[0:2], preserve_range=True)\n",
        "    images[i] = transformed_img\n",
        "#images /= 255.0\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
            "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MHuCXvSMzERG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def scale(X, x_min, x_max):\n",
        "#     nom = (X-X.min(axis=0))*(x_max-x_min)\n",
        "#     denom = X.max(axis=0) - X.min(axis=0)\n",
        "#     denom[denom==0] = 1\n",
        "#     return x_min + nom/denom \n",
        "imagee = images/127.5 -1\n",
        "images = scale(images,-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZQboXXLXjM12",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class GAN:\n",
        "  def __init__(self):\n",
        "    self.img_rows = 128\n",
        "    self.img_cols = 128\n",
        "    self.channels= 3\n",
        "    self.AM = None\n",
        "    self.Disc_Model = None\n",
        "    self.G = None\n",
        "    self.D = None\n",
        "    self.img_shape = (self.img_rows,self.img_cols,self.channels)\n",
        "    self.latent_vector_size = 100\n",
        "    \n",
        "  def combined(self,generator,discriminator):\n",
        "    z = Input(shape= (100,))\n",
        "    optimizer = Adam(0.0002,0.5)\n",
        "    self.generator = self.build_generator()\n",
        "    generated_img = self.generator(z)\n",
        "    self.discriminator = self.build_discriminator()\n",
        "    self.discriminator.compile(loss= \"binary_crossentropy\",optimizer = optimizer,metrics = ['accuracy'])\n",
        "    self.discriminator.trainable = False\n",
        "    valid = self.discriminator(generated_img)\n",
        "    return Model(z,valid)\n",
        "  \n",
        "  def build_generator(self):\n",
        "#     if self.G:\n",
        "#       return self.G\n",
        "    self.G = Sequential()\n",
        "    self.G.add(Conv2D(16, kernel_size = 3, input_shape = (128, 128, 3), padding = \"same\"))\n",
        "    self.G.add(LeakyReLU(alpha = 0.2))\n",
        "    self.G.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "    \n",
        "    self.G.add(Conv2D(8, kernel_size = 3, padding = \"same\"))\n",
        "    self.G.add(LeakyReLU(alpha = 0.2))\n",
        "    self.G.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "    \n",
        "    self.G.add(Conv2D(8, kernel_size = 3, padding = \"valid\"))\n",
        "    self.G.add(LeakyReLU(alpha = 0.2))\n",
        "    self.G.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "    self.G.add(Flatten())\n",
        "\n",
        "    self.G.add(Dense(2048))\n",
        "    self.G.add(Dense(100))\n",
        "    self.G.add(Dense(4096))\n",
        "\n",
        "    self.G.add(Reshape((4, 4, 256)))\n",
        "    self.G.add(UpSampling2D())\n",
        "    self.G.add(Conv2D(256, kernel_size = 3, padding = \"same\"))\n",
        "    self.G.add(LeakyReLU(alpha = 0.2))\n",
        "    self.G.add(UpSampling2D())\n",
        "    self.G.add(Conv2D(16, kernel_size = 3, padding = \"same\"))\n",
        "    self.G.add(LeakyReLU(alpha=0.2))\n",
        "    self.G.add(UpSampling2D())\n",
        "    self.G.add(Conv2D(16, kernel_size = 3, padding = \"same\"))\n",
        "    self.G.add(LeakyReLU(alpha=0.2))\n",
        "    self.G.add(UpSampling2D())\n",
        "    self.G.add(Conv2D(3, kernel_size = 3, padding = \"same\"))\n",
        "\n",
        "    self.G.summary()\n",
        "    z = Input(shape= (100,))\n",
        "    generated_img = self.G(z)\n",
        "    \n",
        "    return Model(z,generated_img)\n",
        "\n",
        "  def build_discriminator(self):\n",
        "#     if self.D:\n",
        "#       return self.D\n",
        "    self.D = Sequential()\n",
        "\n",
        "    self.D.add(Conv2D(64, nb_row=3, nb_col=3, subsample=(2,2), input_shape=self.img_shape, border_mode=\"same\"))\n",
        "    self.D.add(LeakyReLU(alpha=0.2))\n",
        "    self.D.add(Dropout(0.25))\n",
        "    self.D.add(Conv2D(128, nb_row=3, nb_col=3, subsample=(2,2), border_mode=\"same\"))\n",
        "    #model.add(Zeroborder_mode2D(border_mode=((0,1),(0,1))))\n",
        "    self.D.add(BatchNormalization(momentum=0.8))\n",
        "    self.D.add(LeakyReLU(alpha=0.2))\n",
        "    self.D.add(Dropout(0.25))\n",
        "    self.D.add(Conv2D(256, nb_row=3, nb_col=3, subsample=(2,2), border_mode=\"same\"))\n",
        "    self.D.add(BatchNormalization(momentum=0.8))\n",
        "    self.D.add(LeakyReLU(alpha=0.2))\n",
        "    self.D.add(Dropout(0.25))\n",
        "    self.D.add(Conv2D(512, nb_row=3, nb_col=3, subsample=(1,1), border_mode=\"same\"))\n",
        "    self.D.add(BatchNormalization(momentum=0.8))\n",
        "    self.D.add(LeakyReLU(alpha=0.2))\n",
        "    self.D.add(Dropout(0.25))\n",
        "    self.D.add(Flatten())\n",
        "    self.D.add(Dense(1, activation='sigmoid'))\n",
        "    input_image = Input(shape=(128,128,3))\n",
        "    validity= self.D(input_image)\n",
        "    self.D.summary()\n",
        "    return Model(input_image,validity)\n",
        "class DCGAN:\n",
        "  def __init__(self):\n",
        "        self.img_rows = 128\n",
        "        self.img_cols = 128\n",
        "        self.channel = 3\n",
        "\n",
        "        self.x_train = images\n",
        "        self.x_train = self.x_train.reshape(-1, self.img_rows, self.img_cols, 3).astype(np.float32)\n",
        "\n",
        "        self.gan_ = GAN()\n",
        "        self.discriminator_ = self.gan_.build_discriminator()\n",
        "        optimizer = Adam(0.0002,0.5)\n",
        "        self.discriminator_.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "        self.generator_ = self.gan_.build_generator()\n",
        "        self.comb = self.gan_.combined(self.generator_,self.discriminator_)\n",
        "        self.latent_vector_size = 100\n",
        "        self.comb.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "        \n",
        "  def train(self, epochs, batch_size, save_interval,images):\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))    \n",
        "    for epoch in range(epochs):\n",
        "        idx = np.random.randint(0, images.shape[0], batch_size)\n",
        "        imgs = images[idx]\n",
        "        noise = np.random.normal(0, 1, (batch_size, self.latent_vector_size))\n",
        "        gen_imgs = self.generator_.predict(noise)\n",
        "        #plt.imshow(gen_imgs)\n",
        "        d_loss_real = self.discriminator_.train_on_batch(imgs, valid)\n",
        "        d_loss_fake = self.discriminator_.train_on_batch(gen_imgs, fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "        g_loss = self.comb.train_on_batch(noise, valid)\n",
        "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f, G_acc: %.2f%%]\" % (epoch, d_loss[0], d_loss[1], g_loss[0],g_loss[1]))\n",
        "        if epoch % save_interval == 0:\n",
        "            self.save_imgs(epoch)\n",
        "  \n",
        "  def save_imgs(self, epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, self.latent_vector_size))\n",
        "    gen_imgs = self.generator_.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"/content/drive/My Drive/Colab Notebooks/images/DC_GAN_%d.png\" % epoch)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "0fc9f643-2f24-4229-ad09-2171c1502d21",
        "id": "oT7QDuvajM0q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5584
        }
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  dcgan = DCGAN()\n",
        "  dcgan.train(1000, 256, 50,images)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(128, 128,..., strides=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:84: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), strides=(1, 1), padding=\"same\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_41 (Conv2D)           (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 131073    \n",
            "=================================================================\n",
            "Total params: 1,685,633\n",
            "Trainable params: 1,683,841\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (3, 3), padding=\"same\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 2048)              206848    \n",
            "_________________________________________________________________\n",
            "reshape_5 (Reshape)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_21 (UpSampling (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 8, 8, 64)          73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_22 (UpSampling (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_23 (UpSampling (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 32, 32, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_24 (UpSampling (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 64, 64, 16)        4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 64, 64, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_25 (UpSampling (None, 128, 128, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 128, 128, 8)       1160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 128, 128, 8)       32        \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 128, 128, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 128, 128, 3)       219       \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 128, 128, 3)       0         \n",
            "=================================================================\n",
            "Total params: 342,771\n",
            "Trainable params: 342,403\n",
            "Non-trainable params: 368\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 2048)              206848    \n",
            "_________________________________________________________________\n",
            "reshape_6 (Reshape)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_26 (UpSampling (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 8, 8, 64)          73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_27 (UpSampling (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_28 (UpSampling (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 32, 32, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_29 (UpSampling (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 64, 64, 16)        4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 64, 64, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_30 (UpSampling (None, 128, 128, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 128, 128, 8)       1160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 128, 128, 8)       32        \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 128, 128, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 128, 128, 3)       219       \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 128, 128, 3)       0         \n",
            "=================================================================\n",
            "Total params: 342,771\n",
            "Trainable params: 342,403\n",
            "Non-trainable params: 368\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_57 (Conv2D)           (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 131073    \n",
            "=================================================================\n",
            "Total params: 1,685,633\n",
            "Trainable params: 1,683,841\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n",
            "0 [D loss: 4.818251, acc.: 0.27%] [G loss: 0.379152, G_acc: 0.88%]\n",
            "1 [D loss: 0.167942, acc.: 0.96%] [G loss: 0.438291, G_acc: 0.78%]\n",
            "2 [D loss: 1.148232, acc.: 0.49%] [G loss: 0.384415, G_acc: 0.86%]\n",
            "3 [D loss: 0.076303, acc.: 0.99%] [G loss: 0.428019, G_acc: 0.81%]\n",
            "4 [D loss: 0.003976, acc.: 1.00%] [G loss: 0.398710, G_acc: 0.83%]\n",
            "5 [D loss: 0.004722, acc.: 1.00%] [G loss: 0.393682, G_acc: 0.83%]\n",
            "6 [D loss: 0.002399, acc.: 1.00%] [G loss: 0.369333, G_acc: 0.86%]\n",
            "7 [D loss: 0.002661, acc.: 1.00%] [G loss: 0.335264, G_acc: 0.88%]\n",
            "8 [D loss: 0.002562, acc.: 1.00%] [G loss: 0.330989, G_acc: 0.90%]\n",
            "9 [D loss: 0.002487, acc.: 1.00%] [G loss: 0.336456, G_acc: 0.91%]\n",
            "10 [D loss: 0.001681, acc.: 1.00%] [G loss: 0.331923, G_acc: 0.89%]\n",
            "11 [D loss: 0.001681, acc.: 1.00%] [G loss: 0.303456, G_acc: 0.92%]\n",
            "12 [D loss: 0.001526, acc.: 1.00%] [G loss: 0.301474, G_acc: 0.91%]\n",
            "13 [D loss: 0.001352, acc.: 1.00%] [G loss: 0.339512, G_acc: 0.86%]\n",
            "14 [D loss: 0.001463, acc.: 1.00%] [G loss: 0.338827, G_acc: 0.88%]\n",
            "15 [D loss: 0.001252, acc.: 1.00%] [G loss: 0.271193, G_acc: 0.93%]\n",
            "16 [D loss: 0.001316, acc.: 1.00%] [G loss: 0.280865, G_acc: 0.93%]\n",
            "17 [D loss: 0.001114, acc.: 1.00%] [G loss: 0.288450, G_acc: 0.93%]\n",
            "18 [D loss: 0.001030, acc.: 1.00%] [G loss: 0.268772, G_acc: 0.92%]\n",
            "19 [D loss: 0.000896, acc.: 1.00%] [G loss: 0.253118, G_acc: 0.95%]\n",
            "20 [D loss: 0.000919, acc.: 1.00%] [G loss: 0.241833, G_acc: 0.95%]\n",
            "21 [D loss: 0.000870, acc.: 1.00%] [G loss: 0.247188, G_acc: 0.94%]\n",
            "22 [D loss: 0.000872, acc.: 1.00%] [G loss: 0.273885, G_acc: 0.94%]\n",
            "23 [D loss: 0.000879, acc.: 1.00%] [G loss: 0.238803, G_acc: 0.95%]\n",
            "24 [D loss: 0.000751, acc.: 1.00%] [G loss: 0.249114, G_acc: 0.93%]\n",
            "25 [D loss: 0.000762, acc.: 1.00%] [G loss: 0.210999, G_acc: 0.96%]\n",
            "26 [D loss: 0.000638, acc.: 1.00%] [G loss: 0.215288, G_acc: 0.96%]\n",
            "27 [D loss: 0.000660, acc.: 1.00%] [G loss: 0.206392, G_acc: 0.98%]\n",
            "28 [D loss: 0.000662, acc.: 1.00%] [G loss: 0.206253, G_acc: 0.97%]\n",
            "29 [D loss: 0.000840, acc.: 1.00%] [G loss: 0.217249, G_acc: 0.95%]\n",
            "30 [D loss: 0.000572, acc.: 1.00%] [G loss: 0.199052, G_acc: 0.95%]\n",
            "31 [D loss: 0.000596, acc.: 1.00%] [G loss: 0.209653, G_acc: 0.95%]\n",
            "32 [D loss: 0.000479, acc.: 1.00%] [G loss: 0.195317, G_acc: 0.96%]\n",
            "33 [D loss: 0.000496, acc.: 1.00%] [G loss: 0.157708, G_acc: 0.99%]\n",
            "34 [D loss: 0.000462, acc.: 1.00%] [G loss: 0.189492, G_acc: 0.96%]\n",
            "35 [D loss: 0.000408, acc.: 1.00%] [G loss: 0.185506, G_acc: 0.98%]\n",
            "36 [D loss: 0.001003, acc.: 1.00%] [G loss: 0.191389, G_acc: 0.95%]\n",
            "37 [D loss: 0.000467, acc.: 1.00%] [G loss: 0.170808, G_acc: 0.98%]\n",
            "38 [D loss: 0.000365, acc.: 1.00%] [G loss: 0.161938, G_acc: 0.98%]\n",
            "39 [D loss: 0.000596, acc.: 1.00%] [G loss: 0.168483, G_acc: 0.97%]\n",
            "40 [D loss: 0.000436, acc.: 1.00%] [G loss: 0.153429, G_acc: 0.98%]\n",
            "41 [D loss: 0.000364, acc.: 1.00%] [G loss: 0.165970, G_acc: 0.98%]\n",
            "42 [D loss: 0.000371, acc.: 1.00%] [G loss: 0.152241, G_acc: 0.98%]\n",
            "43 [D loss: 0.000359, acc.: 1.00%] [G loss: 0.142806, G_acc: 0.98%]\n",
            "44 [D loss: 0.000303, acc.: 1.00%] [G loss: 0.156089, G_acc: 0.97%]\n",
            "45 [D loss: 0.000318, acc.: 1.00%] [G loss: 0.144069, G_acc: 0.98%]\n",
            "46 [D loss: 0.000331, acc.: 1.00%] [G loss: 0.131926, G_acc: 0.99%]\n",
            "47 [D loss: 0.000301, acc.: 1.00%] [G loss: 0.139101, G_acc: 0.99%]\n",
            "48 [D loss: 0.000314, acc.: 1.00%] [G loss: 0.134551, G_acc: 1.00%]\n",
            "49 [D loss: 0.000278, acc.: 1.00%] [G loss: 0.133392, G_acc: 0.99%]\n",
            "50 [D loss: 0.000266, acc.: 1.00%] [G loss: 0.129899, G_acc: 0.99%]\n",
            "51 [D loss: 0.000477, acc.: 1.00%] [G loss: 0.122329, G_acc: 0.99%]\n",
            "52 [D loss: 0.000237, acc.: 1.00%] [G loss: 0.120028, G_acc: 0.99%]\n",
            "53 [D loss: 0.000432, acc.: 1.00%] [G loss: 0.119486, G_acc: 0.99%]\n",
            "54 [D loss: 0.000240, acc.: 1.00%] [G loss: 0.126164, G_acc: 0.98%]\n",
            "55 [D loss: 0.000233, acc.: 1.00%] [G loss: 0.112609, G_acc: 1.00%]\n",
            "56 [D loss: 0.000255, acc.: 1.00%] [G loss: 0.115361, G_acc: 0.99%]\n",
            "57 [D loss: 0.000199, acc.: 1.00%] [G loss: 0.120949, G_acc: 0.99%]\n",
            "58 [D loss: 0.000215, acc.: 1.00%] [G loss: 0.119812, G_acc: 0.99%]\n",
            "59 [D loss: 0.000224, acc.: 1.00%] [G loss: 0.107641, G_acc: 1.00%]\n",
            "60 [D loss: 0.000245, acc.: 1.00%] [G loss: 0.107698, G_acc: 0.99%]\n",
            "61 [D loss: 0.000213, acc.: 1.00%] [G loss: 0.108886, G_acc: 0.99%]\n",
            "62 [D loss: 0.000238, acc.: 1.00%] [G loss: 0.107066, G_acc: 1.00%]\n",
            "63 [D loss: 0.000229, acc.: 1.00%] [G loss: 0.111283, G_acc: 0.99%]\n",
            "64 [D loss: 0.000203, acc.: 1.00%] [G loss: 0.097864, G_acc: 0.99%]\n",
            "65 [D loss: 0.000193, acc.: 1.00%] [G loss: 0.092455, G_acc: 1.00%]\n",
            "66 [D loss: 0.000192, acc.: 1.00%] [G loss: 0.097433, G_acc: 1.00%]\n",
            "67 [D loss: 0.000174, acc.: 1.00%] [G loss: 0.094988, G_acc: 0.99%]\n",
            "68 [D loss: 0.000183, acc.: 1.00%] [G loss: 0.091057, G_acc: 1.00%]\n",
            "69 [D loss: 0.000187, acc.: 1.00%] [G loss: 0.094335, G_acc: 0.99%]\n",
            "70 [D loss: 0.000195, acc.: 1.00%] [G loss: 0.086707, G_acc: 1.00%]\n",
            "71 [D loss: 0.000184, acc.: 1.00%] [G loss: 0.086532, G_acc: 1.00%]\n",
            "72 [D loss: 0.000160, acc.: 1.00%] [G loss: 0.086275, G_acc: 1.00%]\n",
            "73 [D loss: 0.000164, acc.: 1.00%] [G loss: 0.081541, G_acc: 1.00%]\n",
            "74 [D loss: 0.000171, acc.: 1.00%] [G loss: 0.075304, G_acc: 1.00%]\n",
            "75 [D loss: 0.000158, acc.: 1.00%] [G loss: 0.077291, G_acc: 1.00%]\n",
            "76 [D loss: 0.000160, acc.: 1.00%] [G loss: 0.077806, G_acc: 1.00%]\n",
            "77 [D loss: 0.000168, acc.: 1.00%] [G loss: 0.077855, G_acc: 1.00%]\n",
            "78 [D loss: 0.000154, acc.: 1.00%] [G loss: 0.088926, G_acc: 0.99%]\n",
            "79 [D loss: 0.000135, acc.: 1.00%] [G loss: 0.076890, G_acc: 1.00%]\n",
            "80 [D loss: 0.000133, acc.: 1.00%] [G loss: 0.074222, G_acc: 0.99%]\n",
            "81 [D loss: 0.000127, acc.: 1.00%] [G loss: 0.067023, G_acc: 0.99%]\n",
            "82 [D loss: 0.000127, acc.: 1.00%] [G loss: 0.063900, G_acc: 1.00%]\n",
            "83 [D loss: 0.000117, acc.: 1.00%] [G loss: 0.074277, G_acc: 1.00%]\n",
            "84 [D loss: 0.000123, acc.: 1.00%] [G loss: 0.069380, G_acc: 0.99%]\n",
            "85 [D loss: 0.000158, acc.: 1.00%] [G loss: 0.073270, G_acc: 1.00%]\n",
            "86 [D loss: 0.000117, acc.: 1.00%] [G loss: 0.072383, G_acc: 1.00%]\n",
            "87 [D loss: 0.000143, acc.: 1.00%] [G loss: 0.070908, G_acc: 1.00%]\n",
            "88 [D loss: 0.000130, acc.: 1.00%] [G loss: 0.056827, G_acc: 1.00%]\n",
            "89 [D loss: 0.000118, acc.: 1.00%] [G loss: 0.058598, G_acc: 1.00%]\n",
            "90 [D loss: 0.000102, acc.: 1.00%] [G loss: 0.059445, G_acc: 1.00%]\n",
            "91 [D loss: 0.000119, acc.: 1.00%] [G loss: 0.063068, G_acc: 1.00%]\n",
            "92 [D loss: 0.000117, acc.: 1.00%] [G loss: 0.069955, G_acc: 1.00%]\n",
            "93 [D loss: 0.000110, acc.: 1.00%] [G loss: 0.063271, G_acc: 1.00%]\n",
            "94 [D loss: 0.000107, acc.: 1.00%] [G loss: 0.056495, G_acc: 1.00%]\n",
            "95 [D loss: 0.000101, acc.: 1.00%] [G loss: 0.059689, G_acc: 1.00%]\n",
            "96 [D loss: 0.000090, acc.: 1.00%] [G loss: 0.059479, G_acc: 1.00%]\n",
            "97 [D loss: 0.000102, acc.: 1.00%] [G loss: 0.068427, G_acc: 1.00%]\n",
            "98 [D loss: 0.000096, acc.: 1.00%] [G loss: 0.048975, G_acc: 1.00%]\n",
            "99 [D loss: 0.000095, acc.: 1.00%] [G loss: 0.055658, G_acc: 1.00%]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}