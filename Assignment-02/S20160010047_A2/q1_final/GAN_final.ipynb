{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Ag5otWjuNYPl",
        "colab_type": "code",
        "outputId": "b67e5aa5-edea-4cd6-f633-f7814764eae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JvNADFg6xXk8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cd \"/content/drive/My Drive/Colab Notebooks\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9enYIBw3eubo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "OjaUUKE22-OW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/My Drive/Colab Notebooks/faces94\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MJ44I8h73H2i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob as glob\n",
        "image_paths = glob.glob(file_path+'/*/*/*.jp*g')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3CnPboiY3PYV",
        "colab_type": "code",
        "outputId": "6ebb9b51-305c-4479-f79e-098d0669fb87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(image_paths)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3059"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "6sNvbKmD3U2-",
        "colab_type": "code",
        "outputId": "283751a1-235f-4f52-e500-b8962bb43532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import keras\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam,RMSprop\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Convolution2D, Dropout, Flatten, Dense, BatchNormalization, Reshape, UpSampling2D, Activation, AveragePooling2D, MaxPooling2D\n",
        "from keras.optimizers import Adam, sgd\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.regularizers import L1L2\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import transform\n",
        "import sys\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "uNbv2kAlo3_g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zlahk8uu0FVr",
        "colab_type": "code",
        "outputId": "1402e56b-530d-45a3-e711-f1551af911e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "image_transform = (128, 128, 3)\n",
        "images = np.empty((len(image_paths), *image_transform))\n",
        "for i in range(len(image_paths)//3):\n",
        "    img = plt.imread(image_paths[i])\n",
        "    transformed_img = transform.resize(img, image_transform[0:2], preserve_range=True)\n",
        "    images[i] = transformed_img\n",
        "#images /= 255.0\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
            "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MHuCXvSMzERG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def scale(X, x_min, x_max):\n",
        "#     nom = (X-X.min(axis=0))*(x_max-x_min)\n",
        "#     denom = X.max(axis=0) - X.min(axis=0)\n",
        "#     denom[denom==0] = 1\n",
        "#     return x_min + nom/denom \n",
        "imagee = images/127.5 -1\n",
        "images = scale(images,-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wrrVag4SjM2k",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.shuffle(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "71cde82c-4879-4219-c320-99f168933058",
        "id": "iY5X6nKLjM2Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "plt.imshow(images[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efd70740978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBUkNQ0FSw1CQ1DAUJDX+F+x3jFrKCx/XAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "213c5624-6361-4f74-a0fc-622c4a8e5ded",
        "id": "G3PK8MhcjM2M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(images[89])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efd70651668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kGRW5o3RjM2E",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# X_train = images\n",
        "# image_shape= (128,128,3)\n",
        "# shuffled_images = np.empty((900, *image_shape))\n",
        "# for i in range(900):\n",
        "#     shuffled_images[i] = plt.imread(images_paths[i])\n",
        "# plt.imshow(shuffled_images[20].astype(np.uint8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZQboXXLXjM12",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class GAN:\n",
        "  def __init__(self):\n",
        "    self.img_rows = 128\n",
        "    self.img_cols = 128\n",
        "    self.channels= 3\n",
        "    self.AM = None\n",
        "    self.Disc_Model = None\n",
        "    self.G = None\n",
        "    self.D = None\n",
        "    self.img_shape = (self.img_rows,self.img_cols,self.channels)\n",
        "    self.latent_vector_size = 100\n",
        "    \n",
        "  def combined(self,generator,discriminator):\n",
        "    z = Input(shape= (100,))\n",
        "    optimizer = Adam(0.0002,0.5)\n",
        "    self.generator = self.build_generator()\n",
        "    generated_img = self.generator(z)\n",
        "    self.discriminator = self.build_discriminator()\n",
        "    self.discriminator.compile(loss= \"binary_crossentropy\",optimizer = optimizer,metrics = ['accuracy'])\n",
        "    self.discriminator.trainable = False\n",
        "    valid = self.discriminator(generated_img)\n",
        "    return Model(z,valid)\n",
        "  \n",
        "  def build_generator(self):\n",
        "#     if self.G:\n",
        "#       return self.G\n",
        "    self.G = Sequential()\n",
        "\n",
        "    self.G.add(Dense(128*4*4, activation=\"linear\", input_dim=self.latent_vector_size))\n",
        "    self.G.add(Reshape((4, 4, 128)))   \n",
        "    self.G.add(UpSampling2D())\n",
        "    self.G.add(Conv2D(64, nb_row=3, nb_col=3, border_mode=\"same\"))\n",
        "    self.G.add(BatchNormalization(momentum=0.8))\n",
        "    self.G.add(Activation(\"relu\"))\n",
        "    \n",
        "    \n",
        "    self.G.add(UpSampling2D())\n",
        "    self.G.add(Conv2D(64, nb_row=3, nb_col=3, border_mode=\"same\"))\n",
        "    self.G.add(BatchNormalization(momentum=0.8))\n",
        "    self.G.add(Activation(\"relu\"))\n",
        "    \n",
        "    self.G.add(UpSampling2D())\n",
        "    self.G.add(Conv2D(32, nb_row=3, nb_col=3, border_mode=\"same\"))\n",
        "    self.G.add(BatchNormalization(momentum=0.8))\n",
        "    self.G.add(Activation(\"relu\"))\n",
        "    \n",
        "    \n",
        "    self.G.add(UpSampling2D())\n",
        "    self.G.add(Conv2D(16, nb_row=3, nb_col=3, border_mode=\"same\"))\n",
        "    self.G.add(BatchNormalization(momentum=0.8))\n",
        "    self.G.add(Activation(\"relu\"))\n",
        "     \n",
        "    self.G.add(UpSampling2D())\n",
        "    self.G.add(Conv2D(8, nb_row=3, nb_col=3, border_mode=\"same\"))\n",
        "    self.G.add(BatchNormalization(momentum=0.8))\n",
        "    self.G.add(Activation(\"relu\"))\n",
        "    \n",
        "    self.G.add(Conv2D(self.channels, nb_row=3, nb_col=3, border_mode=\"same\"))\n",
        "    self.G.add(Activation(\"sigmoid\"))\n",
        "\n",
        "    self.G.summary()\n",
        "    z = Input(shape= (100,))\n",
        "    generated_img = self.G(z)\n",
        "    \n",
        "    return Model(z,generated_img)\n",
        "\n",
        "  def build_discriminator(self):\n",
        "#     if self.D:\n",
        "#       return self.D\n",
        "    self.D = Sequential()\n",
        "\n",
        "    self.D.add(Conv2D(64, nb_row=3, nb_col=3, subsample=(2,2), input_shape=self.img_shape, border_mode=\"same\"))\n",
        "    self.D.add(LeakyReLU(alpha=0.2))\n",
        "    self.D.add(Dropout(0.25))\n",
        "    self.D.add(Conv2D(128, nb_row=3, nb_col=3, subsample=(2,2), border_mode=\"same\"))\n",
        "    #model.add(Zeroborder_mode2D(border_mode=((0,1),(0,1))))\n",
        "    self.D.add(BatchNormalization(momentum=0.8))\n",
        "    self.D.add(LeakyReLU(alpha=0.2))\n",
        "    self.D.add(Dropout(0.25))\n",
        "    self.D.add(Conv2D(256, nb_row=3, nb_col=3, subsample=(2,2), border_mode=\"same\"))\n",
        "    self.D.add(BatchNormalization(momentum=0.8))\n",
        "    self.D.add(LeakyReLU(alpha=0.2))\n",
        "    self.D.add(Dropout(0.25))\n",
        "    self.D.add(Conv2D(512, nb_row=3, nb_col=3, subsample=(1,1), border_mode=\"same\"))\n",
        "    self.D.add(BatchNormalization(momentum=0.8))\n",
        "    self.D.add(LeakyReLU(alpha=0.2))\n",
        "    self.D.add(Dropout(0.25))\n",
        "    self.D.add(Flatten())\n",
        "    self.D.add(Dense(1, activation='sigmoid'))\n",
        "    input_image = Input(shape=(128,128,3))\n",
        "    validity= self.D(input_image)\n",
        "    self.D.summary()\n",
        "    return Model(input_image,validity)\n",
        "class DCGAN:\n",
        "  def __init__(self):\n",
        "        self.img_rows = 128\n",
        "        self.img_cols = 128\n",
        "        self.channel = 3\n",
        "\n",
        "        self.x_train = images\n",
        "        self.x_train = self.x_train.reshape(-1, self.img_rows, self.img_cols, 3).astype(np.float32)\n",
        "\n",
        "        self.gan_ = GAN()\n",
        "        self.discriminator_ = self.gan_.build_discriminator()\n",
        "        optimizer = Adam(0.0002,0.5)\n",
        "        self.discriminator_.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "        self.generator_ = self.gan_.build_generator()\n",
        "        self.comb = self.gan_.combined(self.generator_,self.discriminator_)\n",
        "        self.latent_vector_size = 100\n",
        "        self.comb.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "        \n",
        "  def train(self, epochs, batch_size, save_interval,images):\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))    \n",
        "    for epoch in range(epochs):\n",
        "        idx = np.random.randint(0, images.shape[0], batch_size)\n",
        "        imgs = images[idx]\n",
        "        noise = np.random.normal(0, 1, (batch_size, self.latent_vector_size))\n",
        "        gen_imgs = self.generator_.predict(noise)\n",
        "        #plt.imshow(gen_imgs)\n",
        "        d_loss_real = self.discriminator_.train_on_batch(imgs, valid)\n",
        "        d_loss_fake = self.discriminator_.train_on_batch(gen_imgs, fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "        g_loss = self.comb.train_on_batch(noise, valid)\n",
        "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f, G_acc: %.2f%%]\" % (epoch, d_loss[0], d_loss[1], g_loss[0],g_loss[1]))\n",
        "        if epoch % save_interval == 0:\n",
        "            self.save_imgs(epoch)\n",
        "  \n",
        "  def save_imgs(self, epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, self.latent_vector_size))\n",
        "    gen_imgs = self.generator_.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"/content/drive/My Drive/Colab Notebooks/images/DC_GAN_%d.png\" % epoch)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "0fc9f643-2f24-4229-ad09-2171c1502d21",
        "id": "oT7QDuvajM0q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5584
        }
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  dcgan = DCGAN()\n",
        "  dcgan.train(1000, 256, 50,images)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(128, 128,..., strides=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:84: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), strides=(1, 1), padding=\"same\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_41 (Conv2D)           (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 131073    \n",
            "=================================================================\n",
            "Total params: 1,685,633\n",
            "Trainable params: 1,683,841\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (3, 3), padding=\"same\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 2048)              206848    \n",
            "_________________________________________________________________\n",
            "reshape_5 (Reshape)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_21 (UpSampling (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 8, 8, 64)          73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_22 (UpSampling (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_23 (UpSampling (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 32, 32, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_24 (UpSampling (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 64, 64, 16)        4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 64, 64, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_25 (UpSampling (None, 128, 128, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 128, 128, 8)       1160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 128, 128, 8)       32        \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 128, 128, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 128, 128, 3)       219       \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 128, 128, 3)       0         \n",
            "=================================================================\n",
            "Total params: 342,771\n",
            "Trainable params: 342,403\n",
            "Non-trainable params: 368\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 2048)              206848    \n",
            "_________________________________________________________________\n",
            "reshape_6 (Reshape)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_26 (UpSampling (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 8, 8, 64)          73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_27 (UpSampling (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_28 (UpSampling (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 32, 32, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_29 (UpSampling (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 64, 64, 16)        4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 64, 64, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_30 (UpSampling (None, 128, 128, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 128, 128, 8)       1160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 128, 128, 8)       32        \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 128, 128, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 128, 128, 3)       219       \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 128, 128, 3)       0         \n",
            "=================================================================\n",
            "Total params: 342,771\n",
            "Trainable params: 342,403\n",
            "Non-trainable params: 368\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_57 (Conv2D)           (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 131073    \n",
            "=================================================================\n",
            "Total params: 1,685,633\n",
            "Trainable params: 1,683,841\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n",
            "0 [D loss: 4.818251, acc.: 0.27%] [G loss: 0.379152, G_acc: 0.88%]\n",
            "1 [D loss: 0.167942, acc.: 0.96%] [G loss: 0.438291, G_acc: 0.78%]\n",
            "2 [D loss: 1.148232, acc.: 0.49%] [G loss: 0.384415, G_acc: 0.86%]\n",
            "3 [D loss: 0.076303, acc.: 0.99%] [G loss: 0.428019, G_acc: 0.81%]\n",
            "4 [D loss: 0.003976, acc.: 1.00%] [G loss: 0.398710, G_acc: 0.83%]\n",
            "5 [D loss: 0.004722, acc.: 1.00%] [G loss: 0.393682, G_acc: 0.83%]\n",
            "6 [D loss: 0.002399, acc.: 1.00%] [G loss: 0.369333, G_acc: 0.86%]\n",
            "7 [D loss: 0.002661, acc.: 1.00%] [G loss: 0.335264, G_acc: 0.88%]\n",
            "8 [D loss: 0.002562, acc.: 1.00%] [G loss: 0.330989, G_acc: 0.90%]\n",
            "9 [D loss: 0.002487, acc.: 1.00%] [G loss: 0.336456, G_acc: 0.91%]\n",
            "10 [D loss: 0.001681, acc.: 1.00%] [G loss: 0.331923, G_acc: 0.89%]\n",
            "11 [D loss: 0.001681, acc.: 1.00%] [G loss: 0.303456, G_acc: 0.92%]\n",
            "12 [D loss: 0.001526, acc.: 1.00%] [G loss: 0.301474, G_acc: 0.91%]\n",
            "13 [D loss: 0.001352, acc.: 1.00%] [G loss: 0.339512, G_acc: 0.86%]\n",
            "14 [D loss: 0.001463, acc.: 1.00%] [G loss: 0.338827, G_acc: 0.88%]\n",
            "15 [D loss: 0.001252, acc.: 1.00%] [G loss: 0.271193, G_acc: 0.93%]\n",
            "16 [D loss: 0.001316, acc.: 1.00%] [G loss: 0.280865, G_acc: 0.93%]\n",
            "17 [D loss: 0.001114, acc.: 1.00%] [G loss: 0.288450, G_acc: 0.93%]\n",
            "18 [D loss: 0.001030, acc.: 1.00%] [G loss: 0.268772, G_acc: 0.92%]\n",
            "19 [D loss: 0.000896, acc.: 1.00%] [G loss: 0.253118, G_acc: 0.95%]\n",
            "20 [D loss: 0.000919, acc.: 1.00%] [G loss: 0.241833, G_acc: 0.95%]\n",
            "21 [D loss: 0.000870, acc.: 1.00%] [G loss: 0.247188, G_acc: 0.94%]\n",
            "22 [D loss: 0.000872, acc.: 1.00%] [G loss: 0.273885, G_acc: 0.94%]\n",
            "23 [D loss: 0.000879, acc.: 1.00%] [G loss: 0.238803, G_acc: 0.95%]\n",
            "24 [D loss: 0.000751, acc.: 1.00%] [G loss: 0.249114, G_acc: 0.93%]\n",
            "25 [D loss: 0.000762, acc.: 1.00%] [G loss: 0.210999, G_acc: 0.96%]\n",
            "26 [D loss: 0.000638, acc.: 1.00%] [G loss: 0.215288, G_acc: 0.96%]\n",
            "27 [D loss: 0.000660, acc.: 1.00%] [G loss: 0.206392, G_acc: 0.98%]\n",
            "28 [D loss: 0.000662, acc.: 1.00%] [G loss: 0.206253, G_acc: 0.97%]\n",
            "29 [D loss: 0.000840, acc.: 1.00%] [G loss: 0.217249, G_acc: 0.95%]\n",
            "30 [D loss: 0.000572, acc.: 1.00%] [G loss: 0.199052, G_acc: 0.95%]\n",
            "31 [D loss: 0.000596, acc.: 1.00%] [G loss: 0.209653, G_acc: 0.95%]\n",
            "32 [D loss: 0.000479, acc.: 1.00%] [G loss: 0.195317, G_acc: 0.96%]\n",
            "33 [D loss: 0.000496, acc.: 1.00%] [G loss: 0.157708, G_acc: 0.99%]\n",
            "34 [D loss: 0.000462, acc.: 1.00%] [G loss: 0.189492, G_acc: 0.96%]\n",
            "35 [D loss: 0.000408, acc.: 1.00%] [G loss: 0.185506, G_acc: 0.98%]\n",
            "36 [D loss: 0.001003, acc.: 1.00%] [G loss: 0.191389, G_acc: 0.95%]\n",
            "37 [D loss: 0.000467, acc.: 1.00%] [G loss: 0.170808, G_acc: 0.98%]\n",
            "38 [D loss: 0.000365, acc.: 1.00%] [G loss: 0.161938, G_acc: 0.98%]\n",
            "39 [D loss: 0.000596, acc.: 1.00%] [G loss: 0.168483, G_acc: 0.97%]\n",
            "40 [D loss: 0.000436, acc.: 1.00%] [G loss: 0.153429, G_acc: 0.98%]\n",
            "41 [D loss: 0.000364, acc.: 1.00%] [G loss: 0.165970, G_acc: 0.98%]\n",
            "42 [D loss: 0.000371, acc.: 1.00%] [G loss: 0.152241, G_acc: 0.98%]\n",
            "43 [D loss: 0.000359, acc.: 1.00%] [G loss: 0.142806, G_acc: 0.98%]\n",
            "44 [D loss: 0.000303, acc.: 1.00%] [G loss: 0.156089, G_acc: 0.97%]\n",
            "45 [D loss: 0.000318, acc.: 1.00%] [G loss: 0.144069, G_acc: 0.98%]\n",
            "46 [D loss: 0.000331, acc.: 1.00%] [G loss: 0.131926, G_acc: 0.99%]\n",
            "47 [D loss: 0.000301, acc.: 1.00%] [G loss: 0.139101, G_acc: 0.99%]\n",
            "48 [D loss: 0.000314, acc.: 1.00%] [G loss: 0.134551, G_acc: 1.00%]\n",
            "49 [D loss: 0.000278, acc.: 1.00%] [G loss: 0.133392, G_acc: 0.99%]\n",
            "50 [D loss: 0.000266, acc.: 1.00%] [G loss: 0.129899, G_acc: 0.99%]\n",
            "51 [D loss: 0.000477, acc.: 1.00%] [G loss: 0.122329, G_acc: 0.99%]\n",
            "52 [D loss: 0.000237, acc.: 1.00%] [G loss: 0.120028, G_acc: 0.99%]\n",
            "53 [D loss: 0.000432, acc.: 1.00%] [G loss: 0.119486, G_acc: 0.99%]\n",
            "54 [D loss: 0.000240, acc.: 1.00%] [G loss: 0.126164, G_acc: 0.98%]\n",
            "55 [D loss: 0.000233, acc.: 1.00%] [G loss: 0.112609, G_acc: 1.00%]\n",
            "56 [D loss: 0.000255, acc.: 1.00%] [G loss: 0.115361, G_acc: 0.99%]\n",
            "57 [D loss: 0.000199, acc.: 1.00%] [G loss: 0.120949, G_acc: 0.99%]\n",
            "58 [D loss: 0.000215, acc.: 1.00%] [G loss: 0.119812, G_acc: 0.99%]\n",
            "59 [D loss: 0.000224, acc.: 1.00%] [G loss: 0.107641, G_acc: 1.00%]\n",
            "60 [D loss: 0.000245, acc.: 1.00%] [G loss: 0.107698, G_acc: 0.99%]\n",
            "61 [D loss: 0.000213, acc.: 1.00%] [G loss: 0.108886, G_acc: 0.99%]\n",
            "62 [D loss: 0.000238, acc.: 1.00%] [G loss: 0.107066, G_acc: 1.00%]\n",
            "63 [D loss: 0.000229, acc.: 1.00%] [G loss: 0.111283, G_acc: 0.99%]\n",
            "64 [D loss: 0.000203, acc.: 1.00%] [G loss: 0.097864, G_acc: 0.99%]\n",
            "65 [D loss: 0.000193, acc.: 1.00%] [G loss: 0.092455, G_acc: 1.00%]\n",
            "66 [D loss: 0.000192, acc.: 1.00%] [G loss: 0.097433, G_acc: 1.00%]\n",
            "67 [D loss: 0.000174, acc.: 1.00%] [G loss: 0.094988, G_acc: 0.99%]\n",
            "68 [D loss: 0.000183, acc.: 1.00%] [G loss: 0.091057, G_acc: 1.00%]\n",
            "69 [D loss: 0.000187, acc.: 1.00%] [G loss: 0.094335, G_acc: 0.99%]\n",
            "70 [D loss: 0.000195, acc.: 1.00%] [G loss: 0.086707, G_acc: 1.00%]\n",
            "71 [D loss: 0.000184, acc.: 1.00%] [G loss: 0.086532, G_acc: 1.00%]\n",
            "72 [D loss: 0.000160, acc.: 1.00%] [G loss: 0.086275, G_acc: 1.00%]\n",
            "73 [D loss: 0.000164, acc.: 1.00%] [G loss: 0.081541, G_acc: 1.00%]\n",
            "74 [D loss: 0.000171, acc.: 1.00%] [G loss: 0.075304, G_acc: 1.00%]\n",
            "75 [D loss: 0.000158, acc.: 1.00%] [G loss: 0.077291, G_acc: 1.00%]\n",
            "76 [D loss: 0.000160, acc.: 1.00%] [G loss: 0.077806, G_acc: 1.00%]\n",
            "77 [D loss: 0.000168, acc.: 1.00%] [G loss: 0.077855, G_acc: 1.00%]\n",
            "78 [D loss: 0.000154, acc.: 1.00%] [G loss: 0.088926, G_acc: 0.99%]\n",
            "79 [D loss: 0.000135, acc.: 1.00%] [G loss: 0.076890, G_acc: 1.00%]\n",
            "80 [D loss: 0.000133, acc.: 1.00%] [G loss: 0.074222, G_acc: 0.99%]\n",
            "81 [D loss: 0.000127, acc.: 1.00%] [G loss: 0.067023, G_acc: 0.99%]\n",
            "82 [D loss: 0.000127, acc.: 1.00%] [G loss: 0.063900, G_acc: 1.00%]\n",
            "83 [D loss: 0.000117, acc.: 1.00%] [G loss: 0.074277, G_acc: 1.00%]\n",
            "84 [D loss: 0.000123, acc.: 1.00%] [G loss: 0.069380, G_acc: 0.99%]\n",
            "85 [D loss: 0.000158, acc.: 1.00%] [G loss: 0.073270, G_acc: 1.00%]\n",
            "86 [D loss: 0.000117, acc.: 1.00%] [G loss: 0.072383, G_acc: 1.00%]\n",
            "87 [D loss: 0.000143, acc.: 1.00%] [G loss: 0.070908, G_acc: 1.00%]\n",
            "88 [D loss: 0.000130, acc.: 1.00%] [G loss: 0.056827, G_acc: 1.00%]\n",
            "89 [D loss: 0.000118, acc.: 1.00%] [G loss: 0.058598, G_acc: 1.00%]\n",
            "90 [D loss: 0.000102, acc.: 1.00%] [G loss: 0.059445, G_acc: 1.00%]\n",
            "91 [D loss: 0.000119, acc.: 1.00%] [G loss: 0.063068, G_acc: 1.00%]\n",
            "92 [D loss: 0.000117, acc.: 1.00%] [G loss: 0.069955, G_acc: 1.00%]\n",
            "93 [D loss: 0.000110, acc.: 1.00%] [G loss: 0.063271, G_acc: 1.00%]\n",
            "94 [D loss: 0.000107, acc.: 1.00%] [G loss: 0.056495, G_acc: 1.00%]\n",
            "95 [D loss: 0.000101, acc.: 1.00%] [G loss: 0.059689, G_acc: 1.00%]\n",
            "96 [D loss: 0.000090, acc.: 1.00%] [G loss: 0.059479, G_acc: 1.00%]\n",
            "97 [D loss: 0.000102, acc.: 1.00%] [G loss: 0.068427, G_acc: 1.00%]\n",
            "98 [D loss: 0.000096, acc.: 1.00%] [G loss: 0.048975, G_acc: 1.00%]\n",
            "99 [D loss: 0.000095, acc.: 1.00%] [G loss: 0.055658, G_acc: 1.00%]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-zAyZKryceJl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}