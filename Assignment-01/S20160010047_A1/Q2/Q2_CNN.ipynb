{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sTswQieEx9yM",
    "outputId": "84091908-d969-4bf2-fcbf-f2ef8d13043c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PRcU3K7lT10u"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UIcWJqRx5tq"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split \n",
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o72uEHg7x5ty"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gUl_3094T-iU"
   },
   "source": [
    "## Dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LXANA_3Ax5t0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'E:\\\\STUDY\\\\ACADEMIC\\\\6th sem\\\\DL\\\\Assignment\\\\Assignment-1_Datasets\\\\A1-Q2_Dataset\\\\HumanActionClassification'\n",
    "\n",
    "classes = glob(dataset_path+'/*')\n",
    "num_classes = len(classes)\n",
    "print(num_classes)\n",
    "labels = np.array([], dtype=np.int)\n",
    "for each_class in classes:\n",
    "    each_class = each_class[-1]\n",
    "    num_files = len(glob((dataset_path+'/%s/*.jp*g') % each_class))\n",
    "    labels = np.append(labels, np.array([int(each_class)-1]*num_files))\n",
    "image_file_path = glob(dataset_path+'/*/*.jp*g')\n",
    "#print(image_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bt3UmfdVUYHG"
   },
   "source": [
    "## One-hot encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_5vmFlMx5t7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_labels = np.eye(num_classes)[labels]\n",
    "print(one_hot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwZ2hZJXUp7m"
   },
   "source": [
    "## Resizing images for memory constrains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7sLJe0Hpx5uF"
   },
   "outputs": [],
   "source": [
    "image_transform = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "lXApRTRkx5uH",
    "outputId": "157b83f9-31f2-4878-b945-dfec53de4dae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sai19\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "images = np.empty((len(image_file_path), *image_transform))\n",
    "for i in range(len(image_file_path)):\n",
    "    img = plt.imread(image_file_path[i])\n",
    "    transformed_img = transform.resize(img, image_transform[0:2], preserve_range=True)\n",
    "    images[i] = transformed_img\n",
    "images /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ttLDNw0jU-lw"
   },
   "source": [
    "## Input, Target, Weights, Bias initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "7h6BnLTQx5uM",
    "outputId": "3e272d3c-aaae-408b-f9c3-1746548475b5"
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, (None, *image_transform))\n",
    "y = tf.placeholder(tf.float32, (None, num_classes))\n",
    "\n",
    "# Kernels\n",
    "weight1 = tf.Variable(tf.random_normal([3, 3, 3, 64]))\n",
    "weight2 = tf.Variable(tf.random_normal([3, 3, 64, 128]))\n",
    "weight3 = tf.Variable(tf.random_normal([3, 3, 128, 256]))\n",
    "\n",
    "bias1 = tf.Variable(tf.random_normal([64]))\n",
    "bias2 = tf.Variable(tf.random_normal([128]))\n",
    "bias3 = tf.Variable(tf.random_normal([256]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQMdUg52VR5U"
   },
   "source": [
    "  ##  CNN network  [Convolution, Relu and Pooling block and 1 Fully connected block]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8oDQeqvVPYdS"
   },
   "outputs": [],
   "source": [
    "#layer 1\n",
    "conv2d_1 = tf.nn.conv2d(X, weight1, [1, 2, 2, 1], 'VALID') + bias1\n",
    "relu_1 = tf.nn.relu(conv2d_1)\n",
    "maxpool_1 = tf.nn.max_pool(relu_1, [1, 2, 2, 1], [1, 2, 2, 1], 'VALID')\n",
    "#layer 2\n",
    "conv2d_2 = tf.nn.conv2d(maxpool_1, weight2, [1, 2, 2, 1], 'VALID') + bias2\n",
    "relu_2 = tf.nn.relu(conv2d_2)\n",
    "maxpool_2 = tf.nn.max_pool(relu_2, [1, 2, 2, 1], [1, 2, 2, 1], 'VALID')\n",
    "#layer 3\n",
    "conv2d_3 = tf.nn.conv2d(maxpool_2, weight3, [1, 2, 2, 1], 'VALID') + bias3\n",
    "relu_3 = tf.nn.relu(conv2d_3)\n",
    "maxpool_3 = tf.nn.max_pool(relu_3, [1, 2, 2, 1], [1, 2, 2, 1], 'VALID')\n",
    "\n",
    "#fully connected layer\n",
    "flatten_layer = tf.layers.Flatten()(maxpool_3)\n",
    "\n",
    "output = tf.layers.Dense(num_classes)(flatten_layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ##  Loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y, labels=output))\n",
    "#optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.003)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "predicted_ouptut = tf.equal(tf.argmax(y,1), tf.argmax(output,1))\n",
    "acc = tf.reduce_mean(tf.cast(predicted_ouptut, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urcBPEUZx5uS"
   },
   "outputs": [],
   "source": [
    "#initializing variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "444QhhKlVrLq"
   },
   "source": [
    "## Number of Epochs and Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8Yx822ix5uZ"
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h27iAVCTVwPd"
   },
   "source": [
    "## Shuffling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osLzAdwP5yrF"
   },
   "outputs": [],
   "source": [
    "random_indexes = np.random.randint(0, len(image_file_path), (len(image_file_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3IgaRm_y6u-G"
   },
   "outputs": [],
   "source": [
    "images = images[random_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4TBV9c_V12w"
   },
   "source": [
    "## Split Train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O6ac4rt85sL0"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, one_hot_labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mrUAAULmEYc0"
   },
   "outputs": [],
   "source": [
    "del images\n",
    "del labels\n",
    "del image_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mN4uExiSrq61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sai19\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "    sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pAt31qOjV8VE"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3377
    },
    "colab_type": "code",
    "id": "wEb20UaZx5ub",
    "outputId": "03094ad4-bf8b-4c70-b760-40c5c8549118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, Loss -1199386.875000, Training Accuracy 0.14062\n",
      "epoch 2, Loss -6742236.000000, Training Accuracy 0.14062\n",
      "epoch 3, Loss -27947736.000000, Training Accuracy 0.14062\n",
      "epoch 4, Loss -96593536.000000, Training Accuracy 0.14062\n",
      "epoch 5, Loss -285893984.000000, Training Accuracy 0.14062\n",
      "epoch 6, Loss -739860608.000000, Training Accuracy 0.14062\n",
      "epoch 7, Loss -1712280576.000000, Training Accuracy 0.15625\n",
      "epoch 8, Loss -3608528384.000000, Training Accuracy 0.14062\n",
      "epoch 9, Loss -7030492672.000000, Training Accuracy 0.14062\n",
      "epoch 10, Loss -12777943040.000000, Training Accuracy 0.14062\n",
      "epoch 11, Loss -21901180928.000000, Training Accuracy 0.12500\n",
      "epoch 12, Loss -35691388928.000000, Training Accuracy 0.12500\n",
      "epoch 13, Loss -55745785856.000000, Training Accuracy 0.17188\n",
      "epoch 14, Loss -83911262208.000000, Training Accuracy 0.14062\n",
      "epoch 15, Loss -122292027392.000000, Training Accuracy 0.17188\n",
      "epoch 16, Loss -173274628096.000000, Training Accuracy 0.14062\n",
      "epoch 17, Loss -239510945792.000000, Training Accuracy 0.12500\n",
      "epoch 18, Loss -323924262912.000000, Training Accuracy 0.14062\n",
      "epoch 19, Loss -429704740864.000000, Training Accuracy 0.14062\n",
      "epoch 20, Loss -560293019648.000000, Training Accuracy 0.14062\n",
      "epoch 21, Loss -719377137664.000000, Training Accuracy 0.14062\n",
      "epoch 22, Loss -910887485440.000000, Training Accuracy 0.15625\n",
      "epoch 23, Loss -1138992349184.000000, Training Accuracy 0.15625\n",
      "epoch 24, Loss -1408092864512.000000, Training Accuracy 0.14062\n",
      "epoch 25, Loss -1722845626368.000000, Training Accuracy 0.14062\n",
      "epoch 26, Loss -2088145518592.000000, Training Accuracy 0.15625\n",
      "epoch 27, Loss -2509085081600.000000, Training Accuracy 0.12500\n",
      "epoch 28, Loss -2990957658112.000000, Training Accuracy 0.12500\n",
      "epoch 29, Loss -3539258834944.000000, Training Accuracy 0.12500\n",
      "epoch 30, Loss -4159682379776.000000, Training Accuracy 0.12500\n",
      "epoch 31, Loss -4858116571136.000000, Training Accuracy 0.12500\n",
      "epoch 32, Loss -5640638431232.000000, Training Accuracy 0.14062\n",
      "epoch 33, Loss -6513509269504.000000, Training Accuracy 0.14062\n",
      "epoch 34, Loss -7483168391168.000000, Training Accuracy 0.14062\n",
      "epoch 35, Loss -8556228640768.000000, Training Accuracy 0.14062\n",
      "epoch 36, Loss -9739477975040.000000, Training Accuracy 0.14062\n",
      "epoch 37, Loss -11039860064256.000000, Training Accuracy 0.14062\n",
      "epoch 38, Loss -12464486875136.000000, Training Accuracy 0.14062\n",
      "epoch 39, Loss -14020626087936.000000, Training Accuracy 0.12500\n",
      "epoch 40, Loss -15715694280704.000000, Training Accuracy 0.12500\n",
      "epoch 41, Loss -17557256929280.000000, Training Accuracy 0.12500\n",
      "epoch 42, Loss -19553025261568.000000, Training Accuracy 0.12500\n",
      "epoch 43, Loss -21710847868928.000000, Training Accuracy 0.12500\n",
      "epoch 44, Loss -24038718046208.000000, Training Accuracy 0.12500\n",
      "epoch 45, Loss -26544743383040.000000, Training Accuracy 0.12500\n",
      "epoch 46, Loss -29237180366848.000000, Training Accuracy 0.12500\n",
      "epoch 47, Loss -32124405022720.000000, Training Accuracy 0.12500\n",
      "epoch 48, Loss -35214915010560.000000, Training Accuracy 0.12500\n",
      "epoch 49, Loss -38517317042176.000000, Training Accuracy 0.12500\n",
      "epoch 50, Loss -42040339464192.000000, Training Accuracy 0.12500\n",
      "epoch 51, Loss -45792840646656.000000, Training Accuracy 0.12500\n",
      "epoch 52, Loss -49783754457088.000000, Training Accuracy 0.12500\n",
      "epoch 53, Loss -54022157369344.000000, Training Accuracy 0.12500\n",
      "epoch 54, Loss -58517188771840.000000, Training Accuracy 0.12500\n",
      "epoch 55, Loss -63278118076416.000000, Training Accuracy 0.12500\n",
      "epoch 56, Loss -68314306969600.000000, Training Accuracy 0.12500\n",
      "epoch 57, Loss -73635201024000.000000, Training Accuracy 0.12500\n",
      "epoch 58, Loss -79250359058432.000000, Training Accuracy 0.12500\n",
      "epoch 59, Loss -85169394417664.000000, Training Accuracy 0.12500\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []\n",
    "sess.run(init)\n",
    "for i in range(epochs):\n",
    "    for batch in range(len(x_train)//batch_size):\n",
    "        batch_x = x_train[batch*batch_size:min((batch+1)*batch_size,len(x_train))]\n",
    "        batch_y = y_train[batch*batch_size:min((batch+1)*batch_size,len(y_train))]\n",
    "        _ = sess.run(train, feed_dict={X:batch_x,y:batch_y})\n",
    "        loss_, accuracy = sess.run([loss, acc], feed_dict={X: batch_x,y: batch_y})\n",
    "    print('epoch '+str(i+1)+', Loss '+'{:.6f}'.format(loss_)+', Training Accuracy '+'{:.5f}'.format(accuracy))\n",
    "    train_loss.append(loss_)\n",
    "    train_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKhwsopMWBTQ"
   },
   "source": [
    "## Plotting the loss and accuracy for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "colab_type": "code",
    "id": "rA5mjT0zx5ud",
    "outputId": "7ed82236-dbfc-4475-8920-f637a6f988a5"
   },
   "outputs": [],
   "source": [
    "X = np.arange(1, epochs+1)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim((0, 200.0))\n",
    "plt.plot(X, train_loss)\n",
    "plt.title('Training Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "colab_type": "code",
    "id": "HI866hZfXbq7",
    "outputId": "9951ef3e-e314-4543-9542-0ace430490f4"
   },
   "outputs": [],
   "source": [
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(X, train_accuracy)\n",
    "plt.title('Training Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "idROZX6VWa7Y"
   },
   "source": [
    "## Test data loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4vI_fSDJrwPY"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = sess.run([loss, acc], feed_dict={X:x_test[:], y:y_test[:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2jwDLom_LpiO",
    "outputId": "374ddf2b-c85e-407e-f1b5-825d6a4bef57"
   },
   "outputs": [],
   "source": [
    "print('Test loss: %f accuracy: %f' % (test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XeEXjaeUswQj"
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HumanActionClassification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
